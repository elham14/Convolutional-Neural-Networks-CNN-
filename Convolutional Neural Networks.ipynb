{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import load_img, array_to_img, image\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications import vgg16\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21747908e10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_hight,image_width=28,28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(60000,image_hight*image_width)\n",
    "X_test = X_test.reshape(10000, image_hight*image_width)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
      " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
      " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
      "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
      "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
      " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
      " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
      " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
      "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
      " 0.49411765 0.53333336 0.6862745  0.10196079 0.6509804  1.\n",
      " 0.96862745 0.49803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
      " 0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19215687\n",
      " 0.93333334 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.9843137  0.3647059  0.32156864\n",
      " 0.32156864 0.21960784 0.15294118 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07058824 0.85882354 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.7764706  0.7137255\n",
      " 0.96862745 0.94509804 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
      " 0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05490196 0.00392157 0.6039216  0.99215686 0.3529412\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.54509807 0.99215686 0.74509805 0.00784314 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04313726\n",
      " 0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.13725491 0.94509804\n",
      " 0.88235295 0.627451   0.42352942 0.00392157 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.31764707 0.9411765  0.99215686\n",
      " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
      " 0.5882353  0.10588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0627451  0.3647059  0.9882353  0.99215686 0.73333335\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.9764706  0.99215686 0.9764706  0.2509804  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
      " 0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15294118 0.5803922\n",
      " 0.8980392  0.99215686 0.99215686 0.99215686 0.98039216 0.7137255\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09411765 0.44705883 0.8666667  0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.7882353  0.30588236 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07058824 0.67058825\n",
      " 0.85882354 0.99215686 0.99215686 0.99215686 0.99215686 0.7647059\n",
      " 0.3137255  0.03529412 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.21568628 0.6745098  0.8862745  0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.95686275 0.52156866 0.04313726 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53333336 0.99215686\n",
      " 0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.astype('float32')\n",
    "X_test=X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "print(X_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train=to_categorical(y_train,10)\n",
    "print(y_train.shape)\n",
    "y_test=to_categorical(y_test,10)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Roz5\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 22s 374us/step - loss: 0.1805 - accuracy: 0.9445 - val_loss: 0.1131 - val_accuracy: 0.9631\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 23s 386us/step - loss: 0.0806 - accuracy: 0.9747 - val_loss: 0.0833 - val_accuracy: 0.9747\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 24s 395us/step - loss: 0.0551 - accuracy: 0.9828 - val_loss: 0.0856 - val_accuracy: 0.9731\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.0409 - accuracy: 0.9866 - val_loss: 0.0837 - val_accuracy: 0.9772\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 24s 401us/step - loss: 0.0357 - accuracy: 0.9886 - val_loss: 0.0818 - val_accuracy: 0.9778\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 25s 424us/step - loss: 0.0291 - accuracy: 0.9905 - val_loss: 0.0778 - val_accuracy: 0.9793\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 24s 399us/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.0962 - val_accuracy: 0.9798\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 24s 393us/step - loss: 0.0219 - accuracy: 0.9929 - val_loss: 0.1175 - val_accuracy: 0.9745\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 23s 382us/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.1013 - val_accuracy: 0.9793\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 23s 392us/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0974 - val_accuracy: 0.9813\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21747152d68>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Conv2D(32, (5,5), input_shape=(28,28,1), padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Roz5\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn.add(MaxPooling2D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Conv2D(64, (5,5), padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(MaxPooling2D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(1024, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              3212288   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,274,634\n",
      "Trainable params: 3,274,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
